<!DOCTYPE html>
<html lang='en'>

<head>
    <base href=".">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Conference Template</title>
</head>

<body>

    <div class="banner">
        <img src="assets/WCCI_banner.jpg" alt="Conference Template Banner">
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a class="current" title="Conference Home Page" href=".">Home</a>
            </td>
            <td class="navigation">
                <a title="Directions to the Conference" href="directions">Directions</a>
            </td>
            <td class="navigation">
                <a title="Conference Flyer" href="flyer">Flyer</a>
            </td>
        </tr>
    </table>

    <h2>Abstract & Leaning Objectives</h2>
    <p>
        Artificial Intelligence (AI) ethics is a critical and rapidly evolving domain, with fairness and explainability as its foundational pillars. 
        Many papers and books have been published by researchers and practitioners from different communities, 
        addressing different aspects of fair machine learning (FairML) and explainable AI (XAI). 
        However, different papers seem to focus on different definitions of fairness and explainability and propose different assessment criteria.
    </p>
    <p>
        An ML model may appear fair according to one assessment criterion but be simultaneously judged unfair
        according to another. Furthermore, it is not entirely clear what XAI really means. This tutorial provides a
        structured deep dive into these challenges. We will first offer a brief overview of AI ethics. Then, we will
        introduce the diverse definitions and measurement criteria for fairness in machine learning, explore multiobjective approaches to FairML, and highlight specific fairness concerns in modern systems like Large
        Language Models (LLMs) and AI in gaming. Finally, we will articulate what explainability means to different
        people, at different times and for different purposes, how evolutionary multi-objective optimisation could be
        used naturally to enhance explainability of machine learning models, and how XAI techniques can be used
        to enhance the performance of evolutionary algorithms. The tutorial will conclude by synthesizing the
        interesting synergies between FairML, XAI, and evolutionary computation, suggesting directions for future
        research and practice.
    </p>

    <h2>Organizers and Speakers</h2>
    <p>
        Changwu Huang received the Bachelor’s degree from Southwest Jiaotong University, Chengdu, China, in
        2010, the Master’s degree from Beijing Jiaotong University, Beijing, China, in 2013, and the Ph.D. degree
        from Institut National des Sciences Appliquées de Rouen Normandie (INSA Rouen Normandie), Rouen,
        France, in 2018. He is currently a Research Associate Professor at the Department of Computer Science and
        Engineering of Southern University of Science and Technology, Shenzhen, China. His research interests
        mainly include Artificial Intelligence Ethics, Trustworthy Artificial Intelligence, Evolutionary Computation,
        and their practical applications.
    </p>

    <p>
        Jim Tørresen received the M.Sc. degree in computer architecture and design from the Norwegian University
        of Science and Technology, in 1991, and the Dr. (Ing.) (Ph.D.) degree in computer architecture and design
        from the University of Trondheim, in 1996. He is currently a Full Professor with the Department of
        Informatics, University of Oslo, and a Principal Investigator with the RITMO Centre for Interdisciplinary
        Studies in Rhythm, Time and Motion. His research interests include artificial intelligence, ethical aspects of
        AI and robotics, machine learning, robotics, and applying this to complex real-world applications. He is a
        member of the Norwegian Academy of Technological Sciences (NTVA) and the National Committee for
        Research Ethics in Science and Technology (NENT).
    </p>
   
    <p>
        Jialin Liu received her PhD in 2016 from Université Paris-Saclay, MSc in 2013 from École Polytechnique
        & Université Paris-Sud, France, Diplôme d'Ingénieur in 2012 from Polytech'Paris-Sud, France, and BSc in
        2010 from Huazhong University of Science and Technology, China. Currently, Jialin is an Associate
        Professor at the School of Data Science of the Lingnan University, Hong Kong SAR, China. Her main
        research interests include, but not limited to, AI in games, optimisation and learning under uncertainty,
        evolutionary computation and its applications, and fair machine learning. She is an Associate Editor of the
        IEEE Transactions on Games, IEEE Transactions on Evolutionary Computation, and IEEE Transactions on
        Artificial Intelligence. She has co-organised the tutorial “Evolutionary Computation for Games : Learning,
        Planning, and Designing” at IEEE CEC2020. She has given a keynote at the IEEE CEC2024.
    </p>

    <p>
        Xin Yao received the B.Sc. degree from the University of Science and Technology of China (USTC), Hefei,
        China, in 1982, the M.Sc. degree from the North China Institute of Computing Technologies, Beijing, China,
        in 1985, and the Ph.D. degree from USTC, in 1990. Currently, he is a Vice President (Research and Innovation)
        and a Tong Tin Sun Chair Professor of Machine Learning with Lingnan University, Hong Kong SAR, China.
        His major research interests include evolutionary computation, routing optimisation, and trustworthy AI. He
        won the 2001 IEEE Donald G. Fink Prize Paper Award, the 2010, 2016, and 2017 IEEE Transactions on
        Evolutionary Computation Outstanding Paper Awards, the 2011 IEEE Transactions on Neural Networks
        Outstanding Paper Award. He received the 2012 Royal Society Wolfson Research Merit Award, the 2013
        IEEE CIS Evolutionary Computation Pioneer Award, and the 2020 IEEE Frank Rosenblatt Award. He served
        as the President from 2014 to 2015 for IEEE Computational Intelligence Society and an Editor-in-Chief from
        2003 to 2008 for IEEE Transactions on Evolutionary Computation. He is an IEEE Fellow and a Fellow of
        Hong Kong Academy of Engineering.
    </p>


</body>
</html>

